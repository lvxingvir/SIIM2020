{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import urllib\n",
    "import pickle\n",
    "import cv2\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "sys.path.append('./pytorch-auto-augment')\n",
    "from auto_augment import AutoAugment, Cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'C:\\Users\\Xing\\Projects\\SIIM2020\\data_512\\train'\n",
    "test_path = r'C:\\Users\\Xing\\Projects\\SIIM2020\\data_512\\test'\n",
    "train_csv = pd.read_csv(r'C:\\Users\\Xing\\Projects\\SIIM2020\\data\\train.csv')\n",
    "test_csv = pd.read_csv(r'C:\\Users\\Xing\\Projects\\SIIM2020\\data\\test.csv')\n",
    "sample = pd.read_csv(r'C:\\Users\\Xing\\Projects\\SIIM2020\\data\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
       "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
       "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
       "\n",
       "  diagnosis benign_malignant  target  \n",
       "0   unknown           benign       0  \n",
       "1   unknown           benign       0  \n",
       "2     nevus           benign       0  \n",
       "3   unknown           benign       0  \n",
       "4   unknown           benign       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None, test=False):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.df.target.values[idx]\n",
    "        p = self.df.image_name.values[idx]\n",
    "        \n",
    "        if self.test == False:\n",
    "            p_path = os.path.join(train_path,p+'.png')\n",
    "        else:\n",
    "            p_path = os.path.join(test_path,p+'.png')\n",
    "            \n",
    "        image = cv2.imread(p_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(2020)\n",
    "num_classes = 2\n",
    "bs = 80\n",
    "lr = 1e-3\n",
    "IMG_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "testset      = MyDataset(sample, transform=test_transform, test=True)\n",
    "test_loader  = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/332 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "tk = tqdm(train_loader, total=len(train_loader), position=0, leave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tqdm.std.tqdm"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epoch):\n",
    "    model.train() \n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    avg_loss = 0.\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "#     tk = tqdm(train_loader, total=len(train_loader), position=0, leave=True)\n",
    "    for idx, (imgs, labels) in enumerate(train_loader):\n",
    "        print(idx)\n",
    "        imgs_train, labels_train = imgs.cuda(), labels.cuda().long()\n",
    "        output_train = model(imgs_train)\n",
    "\n",
    "        loss = criterion(output_train, labels_train)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "        losses.update(loss.item(), imgs_train.size(0))\n",
    "\n",
    "        tk.set_postfix(loss=losses.avg)\n",
    "        \n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def test_model(model):    \n",
    "    model.eval()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    avg_val_loss = 0.\n",
    "    \n",
    "    valid_preds, valid_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "#         tk = tqdm(val_loader, total=len(val_loader), position=0, leave=True)\n",
    "        for idx, (imgs, labels) in enumerate(val_loader):\n",
    "            imgs_valid, labels_valid = imgs.cuda(), labels.cuda().long()\n",
    "            output_valid = model(imgs_valid)\n",
    "            \n",
    "            loss = criterion(output_valid, labels_valid)\n",
    "            \n",
    "            avg_val_loss += loss.item() / len(val_loader)\n",
    "\n",
    "            losses.update(loss.item(), imgs_valid.size(0))\n",
    "            \n",
    "            tk.set_postfix(loss=losses.avg)\n",
    "            \n",
    "            valid_preds.append(torch.softmax(output_valid,1)[:,1].detach().cpu().numpy())\n",
    "            valid_targets.append(labels_valid.detach().cpu().numpy())\n",
    "            \n",
    "        valid_preds = np.concatenate(valid_preds)\n",
    "        valid_targets = np.concatenate(valid_targets)\n",
    "        auc =  roc_auc_score(valid_targets, valid_preds) \n",
    "            \n",
    "    return avg_val_loss, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "cv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./EfficientUnet-PyTorch/')\n",
    "from efficientunet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-31-d6b6a4fb4fe3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_epochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 38\u001B[1;33m         \u001B[0mavg_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     39\u001B[0m         \u001B[0mavg_val_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mauc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-25-b86fe80ff7a1>\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model, epoch)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;31m#     tk = tqdm(train_loader, total=len(train_loader), position=0, leave=True)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mimgs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0mimgs_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimgs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\env_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    191\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    192\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__iter__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 193\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_DataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    194\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__len__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\env_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m    467\u001B[0m                 \u001B[1;31m#     before it starts, and __del__ tries to join but will get:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    468\u001B[0m                 \u001B[1;31m#     AssertionError: can only join a started process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 469\u001B[1;33m                 \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    470\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex_queues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_queue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    471\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mworkers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\env_torch\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    110\u001B[0m                \u001B[1;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[1;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\env_torch\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    221\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\env_torch\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    320\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    321\u001B[0m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mpopen_spawn_win32\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 322\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m     \u001B[1;32mclass\u001B[0m \u001B[0mSpawnContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\env_torch\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     87\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m                 \u001B[0mset_spawning_popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\env_torch\\lib\\multiprocessing\\reduction.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m     \u001B[0mForkingPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "for trn_ind, val_ind in kf.split(train_csv.image_name, train_csv.target):\n",
    "    fold += 1\n",
    "    print('fold:', fold)\n",
    "\n",
    "    train_df = train_csv.loc[trn_ind]\n",
    "    val_df = train_csv.loc[val_ind]\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    val_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "#     print(train_df)\n",
    "\n",
    "    trainset = MyDataset(train_df, transform=train_transform)\n",
    "#     print(train_set)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=4)\n",
    "   \n",
    "    valset = MyDataset(val_df, transform=test_transform)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=False, num_workers=4)\n",
    "\n",
    "#     model = timm.create_model('tf_efficientnet_b3_ns', pretrained=True, num_classes=num_classes)\n",
    "    model = EfficientNet.from_name('efficientnet-b5', n_classes=2, pretrained=False).cuda()\n",
    "#     model.cuda()\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3,2,1,0'\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model).cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.3)\n",
    "\n",
    "    best_auc = 0\n",
    "    n_epochs = 20\n",
    "    es = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        avg_loss = train_model(model, epoch)\n",
    "        avg_val_loss, auc = test_model(model)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            torch.save(model.state_dict(), str(fold) + 'weight.pt')\n",
    "        else:\n",
    "            es += 1\n",
    "            if es > 1:\n",
    "                break\n",
    "        print('current_val_auc:', auc, 'best_val_auc:', best_auc)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    cv.append(best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "env_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}